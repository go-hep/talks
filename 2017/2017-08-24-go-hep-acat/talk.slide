Go-HEP: writing concurrent software with ease and Go
ACAT-2017, 2017-08-25

Sebastien Binet
CNRS/IN2P3/LPC-Clermont
https://github.com/sbinet
@0xbins
sebastien.binet@clermont.in2p3.fr

* (a brief) History of software in HEP

* 50's-90's: FORTRAN77

.code _code/hello.f

 $ gfortran -c hello.f && gfortran -o hello hello.o
 $ ./hello
 Hello from FORTRAN

- `FORTRAN77` is the *king*
- 1964: *CERNLIB*
- REAP (paper tape measurements), THRESH (geometry reconstruction)
- SUMX, *HBOOK* (statistical analysis chain)
- ZEBRA (memory management, I/O, ...)
- GEANT3, *PAW*

* 90's-...: C++

.code _code/hello.cxx

 $ c++ -o hello hello.cxx && ./hello
 Hello from C++
 
.image _figs/my-root6splash.png 190 190

- object-oriented programming (OOP) is the cool kid on the block
- *ROOT*, POOL, LHC++, AIDA, *Geant4*
- `C++` takes roots in HEP

* 00's-...: python

.code _code/hello.py

 $ python ./hello.py
 Hello from python
 
.image _figs/my-python-logo.png 100 250

- `python` becomes the _de_ _facto_ scripting language in HEP
- framework data-cards
- analysis glue, (whole) analyses in `python`
- *PyROOT*, rootpy
- numpy, scipy, matplotlib, *IPython/Jupyter*

* 

- `C++`: *slow* (very slow?) to compile/develop, *fast* to execute
- `python`: *fast* development cycle (no compilation), *slow* to execute
# (can be mitigated if leveraging/rewriting(parts in) `C++`. more work)

.image _figs/xkcd-compiling.png 400 400

* Other software engineering problems

- scalability (development, teaching, maintenance, build)
- installation of dependencies
- code deployment
- code robustness
- code readability
- multicores/manycores, multithreading
- distributed programming
- etc...

.link https://talks.golang.org/2012/splash.slide
.link https://talks.golang.org/2012/splash.article

* Are those our only options ?

.image _figs/funfast-nogo.svg 500 _

* Let's Go

* What is Go ?

.play _code/hello.go

 $ go run hello.go
 Hello from Go

A nice language with a nice mascot.

.image _figs/golang-logo.png 200 400

* History

- Project starts at Google in 2007 (by Griesemer, Pike, Thompson)
- Open source release in November 2009
- More than 850 contributors have joined the project
- Version 1.0 release in March 2012
- Version 1.1 release in May 2013
- _[...]_
- Version 1.6 release in February 2016
- Version 1.7 release in August 2016
- Version 1.8 release in February 2017
- Version 1.9 release in August 2017

.link https://golang.org

* Elements of Go

- Founding fathers: Russ Cox, Robert Griesemer, Ian Lance Taylor, Rob Pike, Ken Thompson


- Concurrent, garbage-collected
- An Open-source general progamming language (BSD-3)
- feel of a *dynamic* *language*: limited verbosity thanks to the _type_ _inference_ _system_, map, slices
- safety of a *static* *type* *system*
- compiled down to machine language (so it is fast, goal is ~10% of C)
- *object-oriented* but w/o classes, *builtin* *reflection*
- first-class functions with *closures*
- implicitly satisfied *interfaces*

Available on all major platforms (`Linux`, `Windows`, `macOS`, `Android`, `iOS`, ...) and for many architectures (`amd64`, `arm`, `arm64`, `i386`, `s390x`, `mips64`, ...)

* Concurrency in Go

* Goroutines

What is a goroutine? It's an independently executing function, launched by a go statement.

It has its own call stack, which grows and shrinks as required.

It's very cheap. It's practical to have thousands, even hundreds of thousands of goroutines.

It's not a thread.

There might be only one thread in a program with thousands of goroutines.

Instead, goroutines are multiplexed dynamically onto threads as needed to keep all the goroutines running.

But if you think of it as a very cheap thread, you won't be far off.


* A simple example

.code _code/concurrency1.go /f START/,/f END/

Function f is launched as 3 different goroutines, all running concurrently:

.play _code/concurrency1.go /main START/,/main END/


* Communication via channels

A channel type specifies a channel value type (and possibly a communication direction):

	chan int
	chan<- string  // send-only channel
	<-chan T       // receive-only channel

A channel is a variable of channel type:

	var ch chan int
	ch := make(chan int)  // declare and initialize with newly made channel

A channel permits _sending_ and _receiving_ values:

	ch <- 1   // send value 1 on channel ch
	x = <-ch  // receive a value from channel ch (and assign to x)

Channel operations synchronize the communicating goroutines.

* Communicating goroutines

Each goroutine sends its results via channel ch:

.code _code/concurrency2.go /f START/,/f END/

The main goroutine receives (and prints) all results from the same channel:

.play _code/concurrency2.go /main START/,/main END/

* Daisy-chain

.play _code/daisy.go /func/,$

* Chinese whispers, gopher style

.image _figs/gophereartrumpet.jpg

* The Go approach

_"Don't_communicate_by_sharing_memory,_share_memory_by_communicating."_


Goroutines and channels make it easy to express complex operations dealing with:

- multiple inputs
- multiple outputs
- timeouts
- failure

And they're fun to use.

* Real-world application?

OK, [[https://golang.org][Go]] is great.

And it's being used by [[https://github.com/golang/go/wiki/GoUsers][many companies]] (beside `Google`): Mozilla, New-York Times, CoreOS, Docker Inc., SpaceX, ...

But what about `HEP`? and `astro/cosmo`?


* Go-HEP

* Go-HEP

[[https://go-hep.org][go-hep.org]] is a set of pure-Go packages providing building blocks to:

- write analyses in Go (histograms, plots, fits, ...)
- write DAQ and monitoring systems in Go
- write fast simulation tools in Go

All of Go-HEP is installable on Linux, macOS, Windows, RPi3, ... like so:

 $> go get go-hep.org/x/hep/...

including (recursively) the dependencies.

No `Makefile`, no `CMakeList.txt`, no `pom.xml`, ...

* Go-HEP packages

- [[https://godoc.org/go-hep.org/x/hep/fads][go-hep.org/x/hep/fads]]: a fast detector simulation toolkit
- [[https://godoc.org/go-hep.org/x/hep/fastjet][go-hep.org/x/hep/fastjet]]: a jet clustering algorithms package (WIP)
- [[https://godoc.org/go-hep.org/x/hep/fit][go-hep.org/x/hep/fit]]: a fitting function toolkit (WIP)
- [[https://godoc.org/go-hep.org/x/hep/fmom][go-hep.org/x/hep/fmom]]: a 4-vectors library
- [[https://godoc.org/go-hep.org/x/hep/fwk][go-hep.org/x/hep/fwk]]: a concurrency-enabled framework
- [[https://godoc.org/go-hep.org/x/hep/hbook][go-hep.org/x/hep/hbook]]: histograms and n-tuples (WIP)
- [[https://godoc.org/go-hep.org/x/hep/hplot][go-hep.org/x/hep/hplot]]: interactive plotting (WIP), SVG, PNG, PDF, LaTeX output
- [[https://godoc.org/go-hep.org/x/hep/hepmc][go-hep.org/x/hep/hepmc]]: HepMC in pure Go (EDM + I/O)
- [[https://godoc.org/go-hep.org/x/hep/hepevt][go-hep.org/x/hep/hepevt]]: HEPEVT bindings
- [[https://godoc.org/go-hep.org/x/hep/heppdt][go-hep.org/x/hep/heppdt]]: HEP particle data table

* Go-HEP packages (cont'd)

- [[https://godoc.org/go-hep.org/x/hep/lcio][go-hep.org/x/hep/lcio]]: read/write support for LCIO event data model
- [[https://godoc.org/go-hep.org/x/hep/lhef][go-hep.org/x/hep/lhef]]: Les Houches Event File format
- [[https://godoc.org/go-hep.org/x/hep/rio][go-hep.org/x/hep/rio]]: go-hep record oriented I/O
- [[https://godoc.org/go-hep.org/x/hep/rootio][go-hep.org/x/hep/rootio]]: a pure Go package for ROOT I/O (WIP)
- [[https://godoc.org/go-hep.org/x/hep/sio][go-hep.org/x/hep/sio]]: basic, low-level, serial I/O used by LCIO
- [[https://godoc.org/go-hep.org/x/hep/slha][go-hep.org/x/hep/slha]]: SUSY Les Houches Accord I/O

* Go-HEP commands

- [[https://godoc.org/go-hep.org/x/hep/cmd/lhef2hepmc][cmd/lhef2hepmc]]: converts LHEF files to HepMC
- [[https://godoc.org/go-hep.org/x/hep/cmd/rio2yoda][cmd/rio2yoda]]: converts `rio` files to [[https://yoda.hepforge.org][YODA]]
- [[https://godoc.org/go-hep.org/x/hep/cmd/root2npy][cmd/root2npy]]: converts `ROOT` TTrees to `NumPy` `.np(y|z)` files
- [[https://godoc.org/go-hep.org/x/hep/cmd/root2yoda][cmd/root2yoda]]: converts `ROOT` files to [[https://yoda.hepforge.org][YODA]]
- [[https://godoc.org/go-hep.org/x/hep/cmd/yoda2rio][cmd/yoda2rio]]: converts YODA files to `rio`
- [[https://godoc.org/go-hep.org/x/hep/rootio/cmd/root-ls][cmd/root-ls]]: inspects `ROOT` files' content
- [[https://godoc.org/go-hep.org/x/hep/rootio/cmd/root-srv][cmd/root-srv]]: web server that displays `ROOT` files' content (plots TH1x, TH2x, TTrees)

* fads

* fads

`fads` is a "FAst Detector Simulation" toolkit.

- morally a translation of [[https://cp3.irmp.ucl.ac.be/projects/delphes][C++-Delphes]] into Go
- uses [[https://go-hep.org/x/hep/fwk][go-hep/fwk]] to expose, manage and harness concurrency into the usual `HEP` event loop (`initialize` | `process-events` | `finalize`)
- uses [[https://go-hep.org/x/hep/hbook][go-hep/hbook]] for histogramming, [[htpps://go-hep.org/x/hep/hepmc][go-hep/hepmc]] for `HepMC` input/output

Code is on github (BSD-3):

.link https://go-hep.org/x/hep/fwk
.link https://go-hep.org/x/hep/fads

Documentation is served by [[https://godoc.org][godoc.org]]:

.link https://godoc.org/go-hep.org/x/hep/fwk
.link https://godoc.org/go-hep.org/x/hep/fads

* go-hep/fads - Installation

As easy as:

  $ export GOPATH=$HOME/dev/gocode
  $ export PATH=$GOPATH/bin:$PATH
  
  $ go get go-hep.org/x/hep/fads/...

Yes, with the ellipsis at the end, to also install sub-packages.

- `go` `get` will recursively download and install all the packages that [[https://go-hep.org/x/hep/fads][go-hep/fads]] depends on. (no `Makefile` needed)

* go-hep/fwk - Concurrency

[[https://go-hep.org/x/hep/fwk][fwk]] enables:

- event-level concurrency
- tasks-level concurrency

[[https://go-hep.org/x/hep/fwk][fwk]] relies on [[https://golang.org][Go]]'s runtime to properly schedule _goroutines_.

For sub-task concurrency, users are by construction required to use [[https://golang.org][Go]]'s constructs (_goroutines_ and _channels_) so everything is consistent *and* the _runtime_ has the *complete* *picture*.

* go-hep/fads - real world use case

- translated [[https://cp3.irmp.ucl.ac.be/projects/delphes][C++-Delphes]]' ATLAS data-card into Go
- [[https://github.com/go-hep/hep/blob/master/fads/cmd/fads-app/main.go][go-hep/fads-app]]
- installation:

  $ go get go-hep.org/x/hep/fads/cmd/fads-app
  $ fads-app -help
  Usage: fads-app [options] <hepmc-input-file>
  
  ex:
   $ fads-app -l=INFO -evtmax=-1 ./testdata/hepmc.data
  
  options:
    -cpu-prof=false: enable CPU profiling
    -evtmax=-1: number of events to process
    -l="INFO": log level (DEBUG|INFO|WARN|ERROR)
    -nprocs=0: number of concurrent events to process

* go-hep/fads - components

- a `HepMC` converter
- particle propagator
- calorimeter simulator
- energy rescaler, momentum smearer
- isolation
- b-tagging, tau-tagging
- jet-finder (reimplementation of FastJet in Go: [[https://go-hep.org/x/hep/fastjet][go-hep/fastjet]])
- histogram service (from [[https://go-hep.org/x/hep/fwk][go-hep/fwk]])

Caveats:

- jet clustering limited to N^3 (slowest and dumbest scheme of `C++-FastJet`)
- but a GSoC-2017 student ([[https://github.com/Bastiantheone][@Bastian]]) is working on providing an improved version

* 


.image _figs/fads-dflow.png 600 600


* Results - testbenches

- Linux: Intel(R) Xeon(R) CPU X5650  @ 2.67GHz, 24 cores, 56Gb RAM
- Linux: Intel(R) Xeon(R) CPU E5-4620 0 @ 2.20GHz, 64 cores, 128Gb RAM

- Delphes, 3.0.12, gcc4.8
- fads, Go-1.9

 $> time delphes ./input.hepmc
 $> time fads-app ./input.hepmc

* 

.image _figs/linux-64-cores-rss.png 600 _

* 

.image _figs/linux-64-cores-hz.png 600 _

* fads: Results & Conclusions

- good RSS scaling
- good CPU scaling

- bit-by-bit matching physics results wrt `Delphes` (up to calorimetry)
- no need to merge output files, less chaotic I/O, less I/O wait

* Rivet & fads

* Rivet

The [[http://rivet.hepforge.org/][Rivet]] toolkit (Robust Independent Validation of Experiment and Theory) is a system for validation of Monte Carlo event generators. It provides a large (and ever growing) set of experimental analyses useful for MC generator development, validation, and tuning, as well as a convenient infrastructure for adding your own analyses.

 $> repeat 10 'time rivet --analysis=MC_GENERIC -q  ./Z-hadronic-LEP.hepmc > /dev/null'
 real=13.32 user=12.97 sys=0.33 CPU=99% MaxRSS=26292
 real=13.31 user=12.93 sys=0.37 CPU=99% MaxRSS=26356
 real=13.29 user=12.93 sys=0.35 CPU=99% MaxRSS=26440
 real=13.31 user=12.95 sys=0.35 CPU=99% MaxRSS=26356
 real=13.29 user=13.01 sys=0.27 CPU=99% MaxRSS=26280
 real=13.31 user=12.97 sys=0.32 CPU=99% MaxRSS=26328
 real=13.35 user=12.93 sys=0.41 CPU=99% MaxRSS=26276
 real=13.30 user=12.96 sys=0.33 CPU=99% MaxRSS=26624
 real=13.30 user=12.93 sys=0.36 CPU=99% MaxRSS=26440
 real=13.35 user=12.98 sys=0.36 CPU=99% MaxRSS=26484

* fads-rivet-mc-generic

Reimplementation on top of [[https://godoc.org/go-hep.org/x/hep/fwk][go-hep/fwk+fads]] of the `MC_GENERIC` analysis.

Bit-to-bit identical results.

 $> go get go-hep.org/x/hep/fads/cmd/fads-rivet-mc-generic
 
 $> repeat 10 'time fads-rivet-mc-generic -nprocs=1 ./Z-hadronic-LEP.hepmc > /dev/null'
 real=6.04 user=5.66 sys=0.12 CPU= 95% MaxRSS=23384
 real=5.70 user=5.62 sys=0.09 CPU=100% MaxRSS=21128
 real=5.71 user=5.58 sys=0.11 CPU= 99% MaxRSS=22208
 real=5.68 user=5.60 sys=0.08 CPU=100% MaxRSS=23156
 real=5.71 user=5.63 sys=0.08 CPU=100% MaxRSS=20672
 real=5.78 user=5.62 sys=0.09 CPU= 98% MaxRSS=22328
 real=5.67 user=5.62 sys=0.05 CPU=100% MaxRSS=20968
 real=5.68 user=5.57 sys=0.07 CPU= 99% MaxRSS=23748
 real=5.70 user=5.60 sys=0.10 CPU=100% MaxRSS=21360
 real=5.72 user=5.65 sys=0.07 CPU=100% MaxRSS=22764


* ROOT I/O

[[https://go-hep.org][Go-HEP]] provides some amount of interoperability with `ROOT` via [[https://go-hep.org/x/hep/rootio]], a pure-Go package (no `C++`, no `ROOT`, no `PyROOT`, just [[https://golang.org][Go]]) that:

- decodes and understands the structure of `TFiles`, `TKeys`, `TDirectory` and `TStreamerInfos`,
- decodes, deserializes `TH1x`, `TH2x`, `TLeaf`, `TBranch` and `TTrees`

For the moment, only the *I* part of ROOT I/O has been implemented (*O* is starting), but it's already quite useful:

- `cmd/root-ls`
- `cmd/root-srv`

* root-srv (served by AppEngine)

.image _figs/root-srv-screenshot.jpg 550 _


* ROOT I/O

 f, err := rootio.Open("my-file.root")
 obj, ok := f.Get("my-tree")
 tree := obj.(rootio.Tree)
 
 type Data struct {
 	I64    int64       `rootio:"Int64"`
 	F64    float64     `rootio:"Float64"`
 	Str    string      `rootio:"Str"`
 	ArrF64 [10]float64 `rootio:"ArrayFloat64"`
 	N      int32       `rootio:"N"`
 	SliF64 []float64   `rootio:"SliceFloat64"`
 }
 
 var data Data
 sc, err := rootio.NewScanner(tree, &data)
 
 for sc.Next() {
 	err := sc.Scan()
 	if err != nil {
 		log.Fatal(err)
 	}
 	fmt.Printf("entry[%d]: %+v\n", sc.Entry(), data)
 }

 
* ROOT I/O features

- read flat TTrees with C/C++ builtins, static/dynamic arrays of C/C++ builtins
- read "event" TTrees with user defined classes containing: `std::vector<T>` (where `T` is a C/C++ builtin or a `std::string`/`TString`), another user defined class, `std::string` or `TString`, static/dynamic arrays of C/C++ builtins and, of course C/C++ builtins

 struct P3 { int32_t Px; double  Py; int32_t Pz; };
 
 struct Event {
   int16_t  I16;  int32_t  I32; int64_t  I64; uint32_t U32;
   float    F32;  double   F64;
   TString  TStr; std::string StdStr;
   P3       P3;
   int16_t  ArrayI16[ARRAYSZ]; int32_t  ArrayI32[ARRAYSZ];
   double   ArrayF64[ARRAYSZ];
   int32_t  N;
   int16_t  *SliceI16;  //[N]
   int32_t  *SliceI32;  //[N]
   double   *SliceF64;  //[N]
   std::vector<int64_t> StlVecI64; std::vector<std::string> StlVecStr;
 };

* ROOT I/O performances

- Input files:

 $> ll *root
 -rw-r--r-- 1 binet binet 686M Aug 16 11:00 f64s-default-compress.root
 -rw-r--r-- 1 binet binet 764M Aug 16 15:39 f64s-no-compress.root
 
 $> root-ls -t f64s-no-compress.root
 === [f64s-no-compress.root] ===
 version: 61002
 TTree       tree          tree    (entries=1000000)
   Scalar_0  "Scalar_0/D"  TBranch
   Scalar_1  "Scalar_1/D"  TBranch
   Scalar_2  "Scalar_2/D"  TBranch
   [...]
   Scalar_98 "Scalar_98/D" TBranch
   Scalar_99 "Scalar_99/D" TBranch

* ROOT - C++

	auto f = TFile::Open(argv[1], "read");
	auto t = (TTree*)f->Get("tree");

	const Long_t BRANCHES= 100;

	Double_t v[BRANCHES] = {0};

	for (int i = 0; i < BRANCHES; i++) {
		auto n = TString::Format("Scalar_%d", i);
		t->SetBranchAddress(n, &v[i]);
	}

	Long_t entries = t->GetEntries();
	Double_t sum = 0;
	for ( Long_t i = 0; i < entries; i++ ) {
		t->GetEntry(i);
		sum += v[0];
	}

	std::cout << "sum= " << sum << "\n";

* Go-HEP/rootio

	f, err := rootio.Open(flag.Arg(0))
	obj, ok := f.Get("tree")
	t := obj.(rootio.Tree)

	var vs [100]float64
	var svars []rootio.ScanVar
	for i := range vs {
		svars = append(svars, rootio.ScanVar{
			Name:  fmt.Sprintf("Scalar_%d", i),
			Value: &vs[i],
		})
	}

	sum := 0.0
	scan, err := rootio.NewScannerVars(t, svars...)
	for scan.Next() {
		err = scan.Scan()
		if err != nil {
			log.Fatal(err)
		}
		sum += vs[0]
	}

	fmt.Printf("sum= %v\n", sum)

* Results -- No Compression

 $> time ./cxx-read-data
 $> time ./go-read-data

 === ROOT === (VMem=517Mb)
 real=6.70 user=6.18 sys=0.51 CPU= 99% MaxRSS=258296
 real=6.84 user=6.32 sys=0.51 CPU= 99% MaxRSS=257748
 real=6.82 user=6.29 sys=0.52 CPU= 99% MaxRSS=258348
 real=6.66 user=6.13 sys=0.53 CPU=100% MaxRSS=258440
 
 === go-hep/rootio === (VMem=43Mb)
 real=12.94 user=12.39 sys=0.56 CPU=100% MaxRSS=42028
 real=12.93 user=12.37 sys=0.56 CPU=100% MaxRSS=42072
 real=12.96 user=12.38 sys=0.58 CPU=100% MaxRSS=41984
 real=12.94 user=12.36 sys=0.57 CPU=100% MaxRSS=42048

* Results -- with default compression

 === ROOT === (VMem=529Mb)
 real=20.61 user=11.86 sys=0.63 CPU=60% MaxRSS=292640
 real=12.56 user=11.54 sys=0.51 CPU=96% MaxRSS=290124
 real=12.04 user=11.50 sys=0.52 CPU=99% MaxRSS=290444
 real=12.05 user=11.54 sys=0.50 CPU=99% MaxRSS=290324
 
 === go-hep/rootio === (VMem=83Mb)
 real=36.43 user=35.20 sys=0.69 CPU= 98% MaxRSS=81196
 real=35.75 user=35.15 sys=0.63 CPU=100% MaxRSS=81644
 real=35.76 user=35.10 sys=0.69 CPU=100% MaxRSS=81856
 real=35.70 user=35.18 sys=0.54 CPU=100% MaxRSS=81944

*Only* ~2 times slower, w/o any optimization wrt baskets buffering, TTreeCache, ...
No concurrency (yet.)

Of course, `go-hep/rootio` provides less features than ROOT, isn't as battle-tested and is probably full of bugs.
But it's in the same order of magnitude, performance-wise.

* Conclusions

[[https://golang.org][Go]] improves on `C/C++/Java/...` and addresses `C/C++` and `python` deficiencies:

- code distribution
- code installation
- compilation/development speed
- runtime speed
- simple language

and:

- serviceable standard library ([[https://golang.org/pkg][stdlib doc]])
- builtin facilities to tackle concurrency programming

* Conclusions

[[https://go-hep.org][Go-HEP]] provides some building blocks that are already competitive with battle-tested C++ programs, both in terms of CPU, memory usage and cores' harnessing.

Further improvements are still necessary in the `ROOT` `I/O` compatibility part:

- performances
- features (write capabilities + more read use-cases)

Further improvements in the Jupyter area are also warranted (but that's tackled by the Go data science community at large.)

* Conclusions

Go is great at writing small and large (concurrent) programs.
Also true for *science-y* programs, even if the amount of libraries can still be improved.

.image _figs/funfast.svg 320 _

Write your next tool/analysis/simulation/software in [[https://golang.org/][Go]]?


* 

.image _figs/golang-logo-seattle.jpeg 550 _
.caption [[https://go-meetups.appspot.com]]

* Acknowledgements / resources

.link https://tour.golang.org
.link https://talks.golang.org/2012/splash.slide
.link https://talks.golang.org/2012/goforc.slide
.link https://talks.golang.org/2012/waza.slide
.link https://talks.golang.org/2012/concurrency.slide
.link https://talks.golang.org/2013/advconc.slide
.link https://talks.golang.org/2014/gocon-tokyo.slide
.link https://talks.golang.org/2015/simplicity-is-complicated.slide
.link https://talks.golang.org/2016/applicative.slide
.link https://agenda.infn.it/getFile.py/access?contribId=24&sessionId=3&resId=0&materialId=slides&confId=11680

